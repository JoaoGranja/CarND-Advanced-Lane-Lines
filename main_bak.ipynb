{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:19:27.806418Z",
     "start_time": "2020-05-14T13:19:26.028101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing some useful packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from helper_functions import *\n",
    "import pickle\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the output directory to be created\n",
    "output_path = \"output_images/camera_calibration\"\n",
    "\n",
    "# Create test_images_output Directory if doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:19:31.648297Z",
     "start_time": "2020-05-14T13:19:27.811639Z"
    }
   },
   "outputs": [],
   "source": [
    "# To avoid running the calibration step everytime, in case the camera coefficients already exist, just load it\n",
    "if os.path.exists('camera_coeff.pkl'):\n",
    "    # Getting back the values:\n",
    "    with open('camera_coeff.pkl', 'rb') as f:  \n",
    "        mtx, dist = pickle.load(f)\n",
    "    \n",
    "else:  \n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(9,6,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "\n",
    "        # Read the image\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # Convert the image to gray scale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard 54 (9*6) corners \n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, append object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            #cv2.imshow('img',img)\n",
    "            #cv2.waitKey(500)\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    # Perform the camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None) \n",
    "\n",
    "    # Store the camera calibration coefficients for future use\n",
    "    with open('camera_coeff.pkl', 'wb') as f:  \n",
    "        pickle.dump([mtx, dist], f)\n",
    "        \n",
    "    # Perform distortion correction on chessboard images to verify if it is doing well\n",
    "\n",
    "    # Step through the list and undistort each image\n",
    "    for fname in images:\n",
    "\n",
    "        # Read the image\n",
    "        image = mpimg.imread(fname)\n",
    "\n",
    "        # Undistort the image an display it \n",
    "        undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "        # Save images on output_path Directory\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "\n",
    "        ax2.imshow(undist)\n",
    "        ax2.set_title('Undistorted Image', fontsize=30)\n",
    "        plt.subplots_adjust(left=0.1, right=0.9, top=1, bottom=0, wspace = 0.1)\n",
    "\n",
    "\n",
    "        plt.savefig(os.path.join(output_path, \"undist_\" + os.path.basename(fname)))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Build a Lane finding Pipeline\n",
    "Build the pipeline and run the solution on all test_images. Make copies into the `test_images_output` directory, and you can use the images in your writeup report.\n",
    "\n",
    "The pipeline will be composed by the following steps:\n",
    "\n",
    "1 - Read and apply a distortion correction to raw images\n",
    "\n",
    "2 - Use color transforms, gradients, etc., to create a thresholded binary image\n",
    "\n",
    "3 - Apply a perspective transform to rectify binary image (\"birds-eye view\")\n",
    "\n",
    "4 - Detect lane pixels and fit to find the lane boundary\n",
    "\n",
    "5 - Determine the curvature of the lane and vehicle position with respect to center \n",
    "\n",
    "6 - Warp the detected lane boundaries back onto the original image\n",
    "\n",
    "7 - Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the directory to be created\n",
    "output_path = \"output_images/test_images\"\n",
    "\n",
    "# Create test_images_output Directory if doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, fname=None, save_image=False):\n",
    "    ## 1 - Apply a distortion correction to raw images ##\n",
    "\n",
    "    # Undistort the image\n",
    "    undist = undistort_image(img, mtx, dist)\n",
    "\n",
    "    ## 2 - Use color transforms, gradients, etc., to create a thresholded binary image ##\n",
    "    ksize = 3 # Sobel kernel size \n",
    "\n",
    "    # Apply each of the gradient thresholding functions\n",
    "    gradx = abs_sobel_thresh(undist, orient='x', sobel_kernel=ksize, thresh=(30, 150))\n",
    "    grady = abs_sobel_thresh(undist, orient='y', sobel_kernel=ksize, thresh=(50, 200))\n",
    "    mag_binary = mag_thresh(undist, sobel_kernel=ksize, mag_thresh=(30, 200))\n",
    "    dir_binary = dir_threshold(undist, sobel_kernel=ksize, thresh=(0.7, 1.2))\n",
    "\n",
    "    # Apply each of the color thresholding functions\n",
    "    colors_binary = hls_select(undist, thresh=(170, 255))\n",
    "\n",
    "    # Combine all of the thresholding binaries\n",
    "    combined = np.zeros_like(gradx)\n",
    "    combined[(colors_binary == 1) | ((mag_binary == 1) & (dir_binary == 1)) | ((gradx == 1) & (grady == 1)) ] = 1\n",
    "\n",
    "    # 3 - Apply a perspective transform to rectify binary image (\"birds-eye view\") ##\n",
    "\n",
    "    src = np.float32([[220, 700],[1100, 700],[590, 450],[690, 450]])\n",
    "    dst = np.float32([[350,img.shape[0]],[950,img.shape[0]],[350,0],[950,0]])\n",
    "\n",
    "    # Get the transform matrix M using the src and dst points\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Get the invert transform matrix M using the src and dst points\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Warp the image to a top-down view\n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    warped = cv2.warpPerspective(undist, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    ## 4 - Detect lane pixels and fit to find the lane boundary ##\n",
    "\n",
    "    #Take the binary image and find the histogram peaks which are good candidates for the left and right lane lines\n",
    "    binary_warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Create a sliding window and find out which activated pixels fall into the window\n",
    "    out_img, left_fit, right_fit, left_fitx, right_fitx, ploty = fit_polynomial(binary_warped, save_image)\n",
    "\n",
    "\n",
    "    ## 5 - Determine the curvature of the lane and vehicle position with respect to center ##\n",
    "\n",
    "    left_curverad, right_curverad = measure_curvature_real(out_img.shape[0], left_fit, right_fit)\n",
    "\n",
    "    radius_curvature = np.int((left_curverad + right_curverad)/2)\n",
    "\n",
    "    rel_vehicle_position = measure_rel_vehicle_position(out_img.shape, left_fit, right_fit)\n",
    "\n",
    "    ## 6 - Warp the detected lane boundaries back onto the original image ##\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, img_size) \n",
    "\n",
    "\n",
    "    ## 7 - Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position ##\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    if save_image:\n",
    "        save_warped_images(output_path, fname, img, warped)\n",
    "        save_lane_lines_image(output_path, fname, out_img)\n",
    "        \n",
    "        print(\"Left radius curvature = \", np.int(left_curverad), 'm', \"Right radius curvature = \", np.int(right_curverad), 'm')\n",
    "        print(\"Radius curvature = \", radius_curvature, 'm')\n",
    "        print(\"Relative vehicle position with respect to the line lane center = \",rel_vehicle_position, 'm')\n",
    "        \n",
    "        save_pipeline_image(output_path, fname, result, radius_curvature, rel_vehicle_position )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:26:17.757281Z",
     "start_time": "2020-05-14T13:26:17.693455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- test_images/test6.jpg -----------------------\n",
      "Left radius curvature =  1737 m Right radius curvature =  1768 m\n",
      "Radius curvature =  1753 m\n",
      "Relative vehicle position with respect to the line lane center =  0.22 m\n",
      "\n",
      "\n",
      "----------------------- test_images/test5.jpg -----------------------\n",
      "Left radius curvature =  4477 m Right radius curvature =  6737 m\n",
      "Radius curvature =  5607 m\n",
      "Relative vehicle position with respect to the line lane center =  0.12 m\n",
      "\n",
      "\n",
      "----------------------- test_images/test4.jpg -----------------------\n",
      "Left radius curvature =  1906 m Right radius curvature =  2080 m\n",
      "Radius curvature =  1993 m\n",
      "Relative vehicle position with respect to the line lane center =  0.26 m\n",
      "\n",
      "\n",
      "----------------------- test_images/test1.jpg -----------------------\n",
      "Left radius curvature =  2630 m Right radius curvature =  2370 m\n",
      "Radius curvature =  2500 m\n",
      "Relative vehicle position with respect to the line lane center =  0.19 m\n",
      "\n",
      "\n",
      "----------------------- test_images/test3.jpg -----------------------\n",
      "Left radius curvature =  2101 m Right radius curvature =  2038 m\n",
      "Radius curvature =  2069 m\n",
      "Relative vehicle position with respect to the line lane center =  0.15 m\n",
      "\n",
      "\n",
      "----------------------- test_images/test2.jpg -----------------------\n",
      "Left radius curvature =  2661 m Right radius curvature =  3254 m\n",
      "Radius curvature =  2958 m\n",
      "Relative vehicle position with respect to the line lane center =  0.29 m\n",
      "\n",
      "\n",
      "----------------------- test_images/straight_lines2.jpg -----------------------\n",
      "Left radius curvature =  5140 m Right radius curvature =  5579 m\n",
      "Radius curvature =  5360 m\n",
      "Relative vehicle position with respect to the line lane center =  0.04 m\n",
      "\n",
      "\n",
      "----------------------- test_images/straight_lines1.jpg -----------------------\n",
      "Left radius curvature =  15039 m Right radius curvature =  2743 m\n",
      "Radius curvature =  8891 m\n",
      "Relative vehicle position with respect to the line lane center =  0.02 m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Make a list of test images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Step through the list and undistort each image\n",
    "for fname in images:\n",
    "#if False:\n",
    "    print(\"-----------------------\", fname, \"-----------------------\")\n",
    "    #fname = \"test_images/test5.jpg\"\n",
    "\n",
    "    # Read the image\n",
    "    img = mpimg.imread(fname)\n",
    "    process_image(img, fname, True)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 -  Test the pipeline on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:44:25.527191Z",
     "start_time": "2020-05-14T13:44:25.087142Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from line import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_out.mp4.\n",
      "Moviepy - Writing video project_video_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_out.mp4\n",
      "CPU times: user 11min 12s, sys: 2min 22s, total: 13min 34s\n",
      "Wall time: 2h 17min 39s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'project_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image((mtx, dist)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test the pipeline on Challenge Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/485 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video challenge_video_out.mp4.\n",
      "Moviepy - Writing video challenge_video_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready challenge_video_out.mp4\n",
      "CPU times: user 3min 1s, sys: 38.7 s, total: 3min 39s\n",
      "Wall time: 19min 38s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'challenge_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(Line(mtx, dist)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1199 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video harder_challenge_video_out.mp4.\n",
      "Moviepy - Writing video harder_challenge_video_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready harder_challenge_video_out.mp4\n",
      "CPU times: user 9min 53s, sys: 2min 12s, total: 12min 5s\n",
      "Wall time: 5min 20s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'harder_challenge_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(Line(mtx, dist)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"harder_challenge_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
